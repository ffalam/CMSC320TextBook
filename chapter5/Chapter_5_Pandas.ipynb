{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# What is Pandas?\n",
        "\n",
        "Pandas is a powerful open-source Python library that provides high-performance, easy-to-use data structures and data analysis tools. The name \"pandas\" comes from \"panel data,\" a term used in econometrics to describe multi-dimensional data. Developed by Wes McKinney in 2008, pandas has become the cornerstone of data manipulation and analysis in the Python ecosystem.\n",
        "\n",
        "At its core, Pandas helps you:\n",
        "\n",
        "* Load, clean, and transform datasets.\n",
        "\n",
        "* Perform statistical operations efficiently.\n",
        "\n",
        "* Handle missing or inconsistent data.\n",
        "\n",
        "* Merge, reshape, and aggregate large datasets.\n",
        "\n",
        "If you have ever worked with spreadsheets in Excel, Pandas offers similar functionality—but with far greater power, speed, and scalability."
      ],
      "metadata": {
        "id": "U2-w0-OAkBxi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Why Use Pandas?\n",
        "Before pandas, data analysis in Python was cumbersome and required jumping between different libraries. Python users relied heavily on lists, dictionaries, and NumPy arrays for handling structured data. While these tools are powerful, they lack built-in functionality for common tasks like handling missing values, grouping data, or joining tables. Pandas solved this by providing:\n",
        "\n",
        "* **Intuitive data structures:** DataFrames and Series that feel familiar to users from various backgrounds, useful for for working with tabular and one-dimensional data.\n",
        "\n",
        "* **Seamless integration:** Works beautifully with other Python data science libraries (NumPy, Matplotlib, etc).\n",
        "\n",
        "* **Powerful data manipulation:** Easy filtering, grouping, and transformation of data\n",
        "\n",
        "* **Performance:** Built on top of highly optimized C code for speed.\n",
        "\n",
        "* **Time series functionality:** Excellent support for working with time-based data\n",
        "\n",
        "* **Ease of Use:** Simplifies complex operations into a few lines of readable code."
      ],
      "metadata": {
        "id": "mV4MSckXks2l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installing Pandas\n",
        "\n",
        "Before using Pandas, you need to install it. If you are using Anaconda, Pandas comes pre-installed. Otherwise, you can install it with:\n",
        "\n",
        "> pip install pandas\n",
        "\n",
        "Or if you're using Anaconda:\n",
        "\n",
        "\n",
        "> conda install pandas\n",
        "\n",
        "\n",
        "To confirm the installation, open a Python shell and type:\n",
        "\n",
        "> import pandas as pd\n",
        "> print(pd.__version__)"
      ],
      "metadata": {
        "id": "3BeHtdh2l1j3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Loading Data with Pandas\n",
        "\n",
        "One of Pandas’ biggest strengths is its ability to easily import/export datasets from multiple formats:\n",
        "\n",
        "* **CSV:** pd.read_csv(\"file.csv\")\n",
        "\n",
        "* **Excel:** pd.read_excel(\"file.xlsx\")\n",
        "\n",
        "* **SQL Databases:** pd.read_sql(query, connection)\n",
        "\n",
        "* **JSON:** pd.read_json(\"file.json\")\n"
      ],
      "metadata": {
        "id": "cdPUUchKrIqj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Example:\n",
        "\n",
        "df = pd.read_csv(\"students.csv\")\n",
        "print(df.head())   # Displays first 5 rows"
      ],
      "metadata": {
        "id": "n-NYVONnrjL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Core Data Structures\n",
        "The strength of Pandas lies in two core objects:\n",
        "1.   **Series:** A one-dimensional labeled array\n",
        "2.   **Dataframe:** A two-dimensional labeled data structure\n",
        "\n",
        "<center>\n",
        "<img src=\"https://miro.medium.com/v2/resize:fit:1400/0*TB7RB0d21huRNGjI.png\" alt=\"Pandas Illustration\" width=\"600\">\n",
        "</center>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "I5QjXvv_l9KZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Series: The One-Dimensional Workhorse\n",
        "A Series is a one-dimensional labeled array that can hold any data type. Think of it as a single column in a spreadsheet.\n",
        "\n",
        "<center>\n",
        "<img src=\"https://www.w3resource.com/w3r_images/pandas-series-add-image-3.svg\" alt=\"Pandas Series\">\n",
        "</center>\n",
        "\n",
        "\n",
        "Here are some examples:"
      ],
      "metadata": {
        "id": "VgO7nuQpnOxV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.Series([10, 20, 30, 40], index=['A', 'B', 'C', 'D'])\n",
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtdoPr2kncL9",
        "outputId": "1b17ea8a-79fb-4dac-d922-7432e4a2aa0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A    10\n",
            "B    20\n",
            "C    30\n",
            "D    40\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Creating a Series from a list\n",
        "temperatures = pd.Series([22, 25, 18, 30, 27],\n",
        "                        index=['Mon', 'Tue', 'Wed', 'Thu', 'Fri'],\n",
        "                        name='Daily_Temps')\n",
        "print(temperatures)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCazvqBBnShP",
        "outputId": "79285864-5e35-4fba-e66e-f4fb856cb238"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon    22\n",
            "Tue    25\n",
            "Wed    18\n",
            "Thu    30\n",
            "Fri    27\n",
            "Name: Daily_Temps, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DataFrame: The Two-Dimensional Powerhouse\n",
        "A DataFrame is a two-dimensional labeled data structure, similar to a table with rows and columns. It is the most commonly used object in Pandas.\n",
        "\n",
        "\n",
        "<center>\n",
        "<img src=\"https://pynative.com/wp-content/uploads/2021/02/dataframe.png\" alt=\"Pandas DF1\" width=\"500\">\n",
        "</center>\n",
        "\n",
        "\n",
        "<center>\n",
        "<img src=\"https://pynative.com/wp-content/uploads/2021/02/pandas-dataframe-from-dictionary.png\" alt=\"Pandas DF2\" width=\"500\">\n",
        "</center>\n",
        "\n",
        "Here are some examples:"
      ],
      "metadata": {
        "id": "S4xnJFzgnf4c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a DataFrame from a dictionary\n",
        "data = {\n",
        "    'Name': ['Alice', 'Bob', 'Charlie', 'Diana'],\n",
        "    'Age': [25, 30, 35, 28],\n",
        "    'City': ['New York', 'London', 'Paris', 'Tokyo']\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(df)"
      ],
      "metadata": {
        "id": "VtpO3KA-przT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a simple dataset\n",
        "data = {\n",
        "    'Product': ['Apple', 'Banana', 'Cherry', 'Date'],\n",
        "    'Price': [1.20, 0.50, 3.00, 2.50],\n",
        "    'Stock': [45, 120, 15, 80]\n",
        "}\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Display basic information\n",
        "print(\"Our DataFrame:\")\n",
        "print(df)\n",
        "print(\"\\nData types:\")\n",
        "print(df.dtypes)\n",
        "print(\"\\nBasic statistics:\")\n",
        "print(df.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cdf6__VHp2DD",
        "outputId": "e8ae2b21-ae31-4674-fb41-b927bdb7a8df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our DataFrame:\n",
            "  Product  Price  Stock\n",
            "0   Apple    1.2     45\n",
            "1  Banana    0.5    120\n",
            "2  Cherry    3.0     15\n",
            "3    Date    2.5     80\n",
            "\n",
            "Data types:\n",
            "Product     object\n",
            "Price      float64\n",
            "Stock        int64\n",
            "dtype: object\n",
            "\n",
            "Basic statistics:\n",
            "         Price       Stock\n",
            "count  4.00000    4.000000\n",
            "mean   1.80000   65.000000\n",
            "std    1.15181   45.276926\n",
            "min    0.50000   15.000000\n",
            "25%    1.02500   37.500000\n",
            "50%    1.85000   62.500000\n",
            "75%    2.62500   90.000000\n",
            "max    3.00000  120.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pandas Basic Operations\n",
        "\n",
        "After reading tabular data as a DataFrame, you would need to have a glimpse of the data. Pandas makes it easy to explore and manipulate. A good first step is to inspect the dataset by previewing how many rows and columns it has, what the column names are, checking dimensions, or reviewing summary information such as data types and statistics. Pandas provides convenient methods for this.\n",
        "\n",
        "\n",
        "##Viewing/Exploring Data\n",
        "\n",
        "<!-- df.head()     # First 5 rows\n",
        "df.tail()     # Last 5 rows\n",
        "df.shape      # Number of rows and columns\n",
        "df.info()     # Data types and non-null values\n",
        "df.describe() # Summary statistics -->\n",
        "\n",
        "\n",
        "| Command         | Description                                                                                   | Default Behavior                    |\n",
        "| --------------- | --------------------------------------------------------------------------------------------- | ----------------------------------- |\n",
        "| `df.head()`     | Displays the **first rows** of the DataFrame. Useful for quickly previewing the dataset.      | Shows **5 rows**                    |\n",
        "| `df.tail()`     | Displays the **last rows** of the DataFrame. Handy for checking the dataset’s ending records. | Shows **5 rows**                    |\n",
        "| `df.shape`      | Returns a tuple `(rows, columns)` representing the **dimensions** of the DataFrame.           | N/A                                 |\n",
        "| `df.info()`     | Shows column names, **data types**, memory usage, and count of non-null values.               | N/A                                 |\n",
        "| `df.dtypes`     | Returns the **data type of each column** in the DataFrame.                                    | N/A                                 |\n",
        "| `df.describe()` | Provides **summary statistics** (mean, std, min, max, quartiles) for numeric columns.         | Includes numeric columns by default |\n",
        "\n",
        "\n",
        "\n",
        "<center>\n",
        "<img src=\"https://cdn.sanity.io/images/oaglaatp/production/b8add8dc0e1c0907a520e9cb2c8f511b0659726c-1200x600.png?w=1200&h=600&auto=format\" alt=\"Pandas DF3\" width=\"500\">\n",
        "</center>\n"
      ],
      "metadata": {
        "id": "J6cTd0FNsFs8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = {\n",
        "    'Name': ['Alice', 'Bob', 'Charlie'],\n",
        "    'Age': [24, 30, 28],\n",
        "    'Salary': [50000, 60000, 55000]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "print(df.head())\n",
        "print(df.shape)\n"
      ],
      "metadata": {
        "id": "HT9PayZlbazn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Selecting and Indexing Data\n",
        "\n",
        "After inspecting the structure of a DataFrame, the next step is often to select specific rows and columns (specific parts of the data). Pandas provides several approaches depending on whether you want to select columns, rows, or filter data based on conditions. It lets you choose columns, rows, or both using labels (loc), integer positions (iloc), or conditions.\n",
        "\n",
        "###**1. Selecting Columns**\n",
        "\n",
        "| Command               | Description                                      |\n",
        "| --------------------- | ------------------------------------------------ |\n",
        "| `df['col']`           | Selects a **single column** as a Series.         |\n",
        "| `df[['col1','col2']]` | Selects **multiple columns** as a new DataFrame. |\n",
        "\n",
        "\n",
        "###**2. Selecting Rows**\n",
        "\n",
        "| Command              | Description                                  |\n",
        "| -------------------- | -------------------------------------------- |\n",
        "| `df.loc[row_label]`  | Select row(s) by **label** (index name).     |\n",
        "| `df.iloc[row_index]` | Select row(s) by **integer position**.       |\n",
        "| `df.loc[0, 'col']`   | Select a **specific value** by row & column. |\n",
        "\n",
        "\n",
        "\n",
        "###**3. Conditional Selection (Filtering)**\n",
        "\n",
        "| Command                                | Description                               |          |\n",
        "| -------------------------------------- | ----------------------------------------- | -------- |\n",
        "| `df[df['col'] > 50]`                   | Returns rows where condition is **True**. |          |\n",
        "| `df[(df['A'] > 50) & (df['B'] < 100)]` | Combine conditions with `&` (and), \\`     | \\` (or). |\n",
        "\n",
        "Follow is an example:"
      ],
      "metadata": {
        "id": "VtE3EapBt9FN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "\n",
        "data = {\n",
        "    'Name': ['Alice', 'Bob', 'Charlie'],\n",
        "    'Age': [24, 30, 28],\n",
        "    'City': ['New York', 'Los Angeles', 'Chicago']\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(df)\n",
        "\n",
        "# Now, to access the columns: Select columns\n",
        "df['Age']\n",
        "df[['Name', 'City']]\n",
        "\n",
        "# Select rows\n",
        "df.iloc[0]        # First row\n",
        "df.iloc[1:3]      # Rows 1–2\n",
        "df.loc[0, 'Name'] # Specific cell\n",
        "\n",
        "# Conditional selection\n",
        "df[df['Age'] > 30]\n",
        "df[(df['Age'] > 30) & (df['City'] == 'Chicago')]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "tPmdaajLuY1B",
        "outputId": "54f73b2b-a325-4652-e538-d838f6f04b74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Name  Age         City\n",
            "0    Alice   24     New York\n",
            "1      Bob   30  Los Angeles\n",
            "2  Charlie   28      Chicago\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Name, Age, City]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3be7ebd6-2494-477e-93c8-0a21e383c133\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Age</th>\n",
              "      <th>City</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3be7ebd6-2494-477e-93c8-0a21e383c133')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3be7ebd6-2494-477e-93c8-0a21e383c133 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3be7ebd6-2494-477e-93c8-0a21e383c133');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Arithmetic Operations and Functions in Pandas\n",
        "\n",
        "So far we explored how to inspect and select data in Pandas. Once you have access to the right rows and columns, the next step is to perform calculations and apply functions. Pandas makes this process very intuitive by allowing you to apply arithmetic directly to DataFrames or Series, and by offering tools like apply(), map(), and applymap() for more flexibility.\n",
        "\n",
        "## Arithmetic Operations on Columns\n",
        "\n",
        "You can directly apply mathematical operations to Pandas Series or DataFrame columns. Operations are vectorized, meaning they are applied element-wise across the column.\n",
        "\n",
        "In below example, you can notice how the operations are automatically applied to each row."
      ],
      "metadata": {
        "id": "NJpkkMwvcTbG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = {\n",
        "    'Name': ['Alice', 'Bob', 'Charlie'],\n",
        "    'Age': [24, 30, 28],\n",
        "    'Salary': [50000, 60000, 55000]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "print(df)\n",
        "\n",
        "# Increase all salaries by 10%\n",
        "df['Salary'] = df['Salary'] * 1.10\n",
        "\n",
        "# Add 5 years to everyone’s age\n",
        "df['Age'] = df['Age'] + 5\n",
        "print(df)"
      ],
      "metadata": {
        "id": "C8WDkGdlclFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Arithmetic Between Columns\n",
        "You can also perform arithmetic between two or more columns to create new features."
      ],
      "metadata": {
        "id": "uUXQ9Iodcx3U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new column 'Income_per_Age'\n",
        "df['Income_per_Age'] = df['Salary'] / df['Age']\n",
        "print(df)"
      ],
      "metadata": {
        "id": "fTt6nukjc2NT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Applying Built-in Pandas/Numpy Functions\n",
        "\n",
        "Pandas integrates with NumPy functions, allowing you to apply common statistics directly.\n"
      ],
      "metadata": {
        "id": "IxIFiA4ic7DW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Calculate average salary\n",
        "print(df['Salary'].mean())\n",
        "\n",
        "# Standard deviation of Age\n",
        "print(df['Age'].std())\n",
        "\n",
        "# Apply numpy square root\n",
        "print(np.sqrt(df['Age']))"
      ],
      "metadata": {
        "id": "42HA1XToc_h8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Applying Functions with **apply()**\n",
        "\n",
        "Sometimes you need custom transformations. The apply() method lets you apply a function to an entire column (Series) or to each row/column in a DataFrame.\n"
      ],
      "metadata": {
        "id": "2kyj2xDbc-n7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply to a Series\n",
        "df['Age_squared'] = df['Age'].apply(lambda x: x**2)\n",
        "\n",
        "# Apply to DataFrame across rows\n",
        "df['Total'] = df[['Age','Salary']].apply(lambda row: row['Age'] + row['Salary'], axis=1)\n",
        "print(df)"
      ],
      "metadata": {
        "id": "CI_UGGeidXH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that, we can also apply a Function Elementwise with applymap() and to a Single Column with map() but not covering in this course."
      ],
      "metadata": {
        "id": "k5ZTacVnucQQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Filtering Data in Pandas\n",
        "\n",
        "Once you know how to select columns and rows, the next step is learning how to filter data. Filtering helps you focus on only the relevant part of your dataset, whether that means removing unnecessary columns, isolating rows that meet certain conditions, or preparing features for modeling.\n",
        "\n",
        "## Filtering Columns\n",
        "\n",
        "Column filtering is about selecting only the columns you need or dropping the ones you don’t. This reduces memory usage and keeps your DataFrame manageable."
      ],
      "metadata": {
        "id": "fyVTfiKTeI04"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select a single column\n",
        "df['Age']\n",
        "\n",
        "# Select multiple columns\n",
        "df[['Name', 'City']]\n",
        "\n"
      ],
      "metadata": {
        "id": "c4v3yYEUeGOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dropping Unused Columns"
      ],
      "metadata": {
        "id": "qR9sZFu5e-pV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the 'City' column\n",
        "df = df.drop(columns=['City'])\n",
        "print(df)"
      ],
      "metadata": {
        "id": "Hso3cwY3fAVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is especially useful when preparing data for machine learning, where only selected features are required."
      ],
      "metadata": {
        "id": "4Uxc9z7sfFg8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Filtering Rows (using Boolean Indexing)\n",
        "\n",
        "Row filtering is usually done with Boolean indexing, where you apply a condition and return only the rows where that condition is true."
      ],
      "metadata": {
        "id": "3fCS_z3jfQAS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter rows where Age > 30\n",
        "df[df['Age'] > 30]"
      ],
      "metadata": {
        "id": "p72rSa8WfbRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Combining Multiple Conditions\n",
        "You can combine conditions using & (and) or | (or)."
      ],
      "metadata": {
        "id": "yYU__Amtfl7D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter rows where Age > 30 AND Salary > 60000\n",
        "df[(df['Age'] > 30) & (df['Salary'] > 60000)]"
      ],
      "metadata": {
        "id": "444QIjbcfpE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "> Remember to wrap each condition in parentheses."
      ],
      "metadata": {
        "id": "MKOpgKEBfy1_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Filtering Strings\n",
        "\n",
        "You can filter rows where a text column contains specific values"
      ],
      "metadata": {
        "id": "35ZeG0GFfuK8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter rows where City contains \"York\"\n",
        "df[df['City'].str.contains(\"York\")]"
      ],
      "metadata": {
        "id": "iE-QQhCogNO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Unique Values and Counting\n",
        "\n",
        "Sometimes you want to check how many unique values a column has, or count how often each appears."
      ],
      "metadata": {
        "id": "1o6BqORKgTgt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Unique cities\n",
        "print(df['City'].unique())\n",
        "\n",
        "# Count frequency of each city\n",
        "print(df['City'].value_counts())\n"
      ],
      "metadata": {
        "id": "rCaQ4dI9fcH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Applying Aggregation Functions Directly to a DataFrame\n",
        "\n",
        "One of the strengths of Pandas is that you can apply statistical and aggregation methods directly to a DataFrame or Series. These methods summarize data and provide insights without needing extra loops or manual calculations.\n",
        "\n",
        "### Common Aggregation Methods\n",
        "\n",
        "Here are some of the most commonly used methods:\n",
        "\n",
        "| Method        | Description                                              | Works On           |\n",
        "|---------------|----------------------------------------------------------|--------------------|\n",
        "| `.sum()`      | Returns the **sum** of values                            | DataFrame / Series |\n",
        "| `.mean()`     | Returns the **average (mean)** value                     | DataFrame / Series |\n",
        "| `.count()`    | Counts **non-null values**                               | DataFrame / Series |\n",
        "| `.min()`      | Returns the **minimum** value                            | DataFrame / Series |\n",
        "| `.max()`      | Returns the **maximum** value                            | DataFrame / Series |\n",
        "| `.std()`      | Returns the **standard deviation**                       | DataFrame / Series |\n",
        "| `.var()`      | Returns the **variance**                                 | DataFrame / Series |\n",
        "| `.describe()` | Generates **summary statistics** (count, mean, std, min, quartiles, max) | DataFrame / Series |\n",
        "\n",
        "\n",
        "Example: Aggregating a Series\n"
      ],
      "metadata": {
        "id": "1R3Q7zkRhRwO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Salary data\n",
        "salaries = pd.Series([50000, 60000, 55000, 65000, 70000])\n",
        "\n",
        "print(\"Sum:\", salaries.sum())\n",
        "print(\"Mean:\", salaries.mean())\n",
        "print(\"Max:\", salaries.max())\n",
        "print(\"Std Dev:\", salaries.std())"
      ],
      "metadata": {
        "id": "lnxZjp8KhtzD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each method is applied directly to the Series, returning a single value."
      ],
      "metadata": {
        "id": "FVJA5pfThk24"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example: Aggregating a DataFrame"
      ],
      "metadata": {
        "id": "O0Gf_RHNhsKb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "    'Name': ['Alice', 'Bob', 'Charlie'],\n",
        "    'Age': [24, 30, 28],\n",
        "    'Salary': [50000, 60000, 55000]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "print(df.sum(numeric_only=True))   # Sum of numeric columns\n",
        "print(df.mean(numeric_only=True))  # Mean of numeric columns\n",
        "print(df.describe())"
      ],
      "metadata": {
        "id": "dkk1yAc2hyuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice how these functions automatically ignore non-numeric columns (like “Name”)."
      ],
      "metadata": {
        "id": "Tj7rAIVYh20H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# More Advanced: Filtering Data & Apply Statistical Functions\n",
        "\n",
        "We can combine **row filtering** with **aggregation functions** to analyze subsets of a DataFrame.  \n",
        "\n",
        "The general syntax is:\n",
        "\n",
        "> **df[df['column_name'] <condition> value]['target_column'].function()**\n",
        "\n",
        "where:\n",
        "\n",
        "- df[...] → filters the rows that meet the condition\n",
        "\n",
        "- ['target_column'] → selects the column to aggregate\n",
        "\n",
        "- .function() → applies the aggregation function\n"
      ],
      "metadata": {
        "id": "eFHc6gW2hIS6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = {\n",
        "    'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
        "    'Age': [24, 35, 28, 40],\n",
        "    'Salary': [50000, 66000, 55000, 70000]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Average salary of employees older than 30\n",
        "avg_salary = df[df['Age'] > 30]['Salary'].mean()\n",
        "print(avg_salary)\n",
        "\n",
        "# Maximum salary for employees younger than 30\n",
        "df[df['Age'] < 30]['Salary'].max()\n",
        "\n",
        "# Count employees with salary above 60,000\n",
        "df[df['Salary'] > 60000]['Name'].count()\n",
        "\n",
        "# Standard deviation of salary for people aged 25–40\n",
        "df[(df['Age'] >= 25) & (df['Age'] <= 40)]['Salary'].std()"
      ],
      "metadata": {
        "id": "k2NT3sxaify4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So the syntax pattern is:\n",
        "\n",
        "df[ df['condition'] ]['column'].aggregation()\n",
        "\n",
        "| Expression                                                  | Meaning                                          |\n",
        "| ----------------------------------------------------------- | ------------------------------------------------ |\n",
        "| `df[df['Age'] > 30]['Salary'].mean()`                       | Mean of Salary where Age > 30                    |\n",
        "| `df[df['Salary'] > 60000]['Name'].count()`                  | Count of employees with Salary > 60k             |\n",
        "| `df[(df['Age'] >= 25) & (df['Age'] <= 40)]['Salary'].std()` | Standard deviation of Salary for 25–40 year olds |\n",
        "\n",
        "\n",
        "This pattern allows you to filter data first, then aggregate only on the rows that meet your condition."
      ],
      "metadata": {
        "id": "a09XGUk-im7D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Grouping Data with `groupby`\n",
        "\n",
        "While filtering + aggregation lets us summarize a **subset** of data, the `groupby()` method allows us to compute statistics **across categories**.  \n",
        "This is the classic **split–apply–combine** process:\n",
        "\n",
        "1. **Split** data into groups based on one or more columns.  \n",
        "2. **Apply** an aggregation function to each group.  \n",
        "3. **Combine** results into a new DataFrame or Series.  \n",
        "\n",
        "---\n",
        "\n",
        "## Basic Syntax\n",
        "\n",
        "> df.groupby('column_name')['target_column'].aggregation_function()\n",
        "where:\n",
        "- `groupby('column_name')` → splits the data into groups.  \n",
        "- `['target_column']` → selects the column to aggregate.  \n",
        "- `.aggregation_function()` → applies functions like `mean()`, `sum()`, `count()`.  \n"
      ],
      "metadata": {
        "id": "ikWl-Qt6jAaW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Example: Salary by Department\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Sample dataset\n",
        "data = {\n",
        "    'Department': ['HR','HR','IT','IT','Finance','Finance'],\n",
        "    'Employee': ['Alice','Bob','Charlie','David','Eva','Frank'],\n",
        "    'Salary': [50000, 52000, 60000, 62000, 58000, 60000]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "print(df)\n",
        "\n",
        "# Average salary per department\n",
        "df.groupby('Department')['Salary'].mean()\n",
        "\n"
      ],
      "metadata": {
        "id": "63Exf7BtjM84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Grouping by Multiple Columns"
      ],
      "metadata": {
        "id": "QW7Ga5CFjV9p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example dataset with Region added\n",
        "data2 = {\n",
        "    'Department': ['HR','HR','IT','IT','Finance','Finance'],\n",
        "    'Region': ['East','West','East','West','East','West'],\n",
        "    'Salary': [50000, 52000, 60000, 62000, 58000, 60000]\n",
        "}\n",
        "df2 = pd.DataFrame(data2)\n",
        "\n",
        "# Group by Department and Region\n",
        "df2.groupby(['Department','Region'])['Salary'].mean()"
      ],
      "metadata": {
        "id": "hoxt1cFIi2j2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "c8GII8KsiyDC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The pandas Ecosystem: How It Fits In\n",
        "\n",
        "Pandas does not exist in a vacuum. It is a central hub in the Python data science stack:\n",
        "\n",
        "* **NumPy:** Provides the foundational n-dimensional array object. Pandas DataFrames are built on top of NumPy arrays.\n",
        "\n",
        "* **Matplotlib/Seaborn:** Used for visualization. You can plot data directly from DataFrames and Series.\n",
        "\n",
        "* **Scikit-learn:** The premier machine learning library. It accepts DataFrames and Series as inputs for model training.\n",
        "\n",
        "* **Jupyter Notebooks:** The ideal interactive environment for exploratory data analysis with pandas."
      ],
      "metadata": {
        "id": "0bXTuPLTqgts"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# When to Use Pandas (And When Not To)\n",
        "\n",
        "##Use pandas when:\n",
        "\n",
        "* Working with tabular data (like spreadsheets or database tables)\n",
        "\n",
        "* Data cleaning and preprocessing\n",
        "\n",
        "* Exploratory data analysis\n",
        "\n",
        "* Medium-sized datasets (up to a few gigabytes)\n",
        "\n",
        "##Consider alternatives when:\n",
        "\n",
        "* Working with very large datasets that don't fit in memory.\n",
        "\n",
        "* Need extremely high performance for numerical computations (consider NumPy directly)\n",
        "\n",
        "* Working with unstructured data like images or text"
      ],
      "metadata": {
        "id": "t64_990fqNPO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Key Takeaways\n",
        "\n",
        "\n",
        "*   Filtering + Aggregation → summarize specific rows based on conditions.\n",
        "*   GroupBy + Aggregation → summarize categories (all groups at once).\n",
        "*   Grouping can be done on one or multiple columns."
      ],
      "metadata": {
        "id": "nGvPQctejcAR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary of Pandas: Key Features at a Glance\n",
        "\n",
        "* **Data Import/Export:** Read from and write to CSV, Excel, SQL, JSON, and many other formats\n",
        "\n",
        "* **Data Cleaning:** Handle missing values, remove duplicates, filter outliers\n",
        "\n",
        "* **Data Transformation:** Reshape, pivot, melt, and transform your data\n",
        "\n",
        "* **Data Aggregation:** Group by categories and compute summary statistics\n",
        "\n",
        "* **Time Series Analysis:** Work with dates and times effortlessly\n",
        "\n",
        "* **Visualization Integration:** Works seamlessly with Matplotlib and Seaborn"
      ],
      "metadata": {
        "id": "G_glPDb6p-1M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "jFBCUx8cm8YG"
      }
    }
  ]
}