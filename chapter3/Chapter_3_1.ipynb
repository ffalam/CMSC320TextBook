{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KQvdqPYPi18_"
   },
   "source": [
    "# Key Ideas in Experimental Design\n",
    "\n",
    "Although experimental design is a broad field, several concepts appear repeatedly in data science applications:\n",
    "\n",
    "## **(I) Hypothesis & Research Question**\n",
    "\n",
    "### **Asking the Right Question**\n",
    "\n",
    "Every experiment begins with **a question**, and asking the right question is important. This is the big-picture motivation behind why we run an experiment at all. It focuses on decision-making, usefulness, and purpose.\n",
    "\n",
    "> “**Data is the new science. Big Data holds the answers. Are you asking the right questions?**”  \n",
    "> — Patrick P. Gelsinger, Former CEO of Intel\n",
    "\n",
    "A data science project is only as valuable as the question it answers. In practice, these questions can have **different decision goals**. Some questions are simple and descriptive, while others help us make better decisions.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Different Decision Goals in Data Science**\n",
    "\n",
    "| Decision Goal | Core Question | Purpose | Example (same scenario) |\n",
    "|---|---|---|---|\n",
    "| **Descriptive** | What happened? | Summarizes past or current state | \"Sales dropped last week.\" |\n",
    "| **Diagnostic** | Why did it happen? | Explains patterns and associations (not causal) | \"Sales dropped because shipping was slow.\" |\n",
    "| **Predictive** | What will happen next? | Forecasts future outcomes | \"If shipping stays slow, sales will continue to drop.\" |\n",
    "| **Causal** | What is the effect of doing X? | Identifies cause–effect relationships under interventions | \"Speeding up shipping increases sales.\" |\n",
    "| **Prescriptive / Optimization** | What should we do? | Chooses the best action to achieve a desired outcome | \"Speeding up shipping is the best way to increase sales.\" |\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://raw.githubusercontent.com/ffalam/CMSC320TextBook/refs/heads/main/chapter3/Type_of_Analysis_Form.png\" width=\"450\"><br>\n",
    "  <em>Figure 2: Hierarchy of decision goals in data science and analytics.</em>\n",
    "</p>\n",
    "\n",
    "As we move from descriptive to diagnostic, predictive, causal, and finally prescriptive/optimization questions, the insights become more useful for real-world decisions, but also harder to answer. Harder questions often require more data, stronger assumptions, better models, and sometimes experiments or interventions to figure out cause and choose the best action.\n",
    "\n",
    "---\n",
    "\n",
    "**What is Optimization?**\n",
    "\n",
    "Optimization is about choosing the **best action** to reach a goal. Goals can vary depending on the context of the problem, such as increasing sales, reducing wait times, improving accuracy, or boosting conversions. Formally, we define an objective \\( f(x) \\) (something we care about) and choose the option that maximizes or minimizes \\( f(x) \\).\n",
    "\n",
    "For example:\n",
    "\n",
    "> “Will showing product reviews increase purchase conversions?”\n",
    "\n",
    "A tech company might test two landing pages to see which one produces a higher click-through rate (CTR). A hospital might test different rehabilitation schedules to see which one speeds recovery. A city might test new traffic signal timings to reduce congestion.\n",
    "\n",
    "---\n",
    "\n",
    "**Connecting Back to Experiments**\n",
    "\n",
    "Before we can optimize, we often need to understand **causal effects** (e.g., “If we change X, what happens to Y?”). This is where experiments come in. Experiments allow us to compare the results of different actions and see which one performs better.\n",
    "\n",
    "At this stage, the goal is not to prove anything mathematically. It is simply to clarify what we want to learn and what outcome matters. These questions are later converted into **testable hypotheses** (null vs. alternative) that allow us to evaluate results.\n",
    "\n",
    "We will discuss null and alternative hypotheses in a *later chapter*.\n",
    "\n",
    "<!-- ### **Asking the Right Question**\n",
    "Every experiment begins with **a question**, and **asking the right question** is important. This is the big-picture question that motivates why we are running an experiment at all. It focuses on decision-making, usefulness, and purpose.\n",
    "\n",
    "> \"**Data is the new science. Big Data holds the answers. Are you asking the right questions?\" - Patrick P. Gelsinger, Former CEO of Intel**\n",
    "\n",
    "\n",
    "A data science project is only as valuable as the question it answers. In practice, these questions can have  **different decision goals**. Some are simple and descriptive; others help us make better decisions. -->\n",
    "\n",
    "\n",
    "<!-- - **Descriptive:** What happened?\n",
    "\n",
    "- **Diagnostic:** What did it happen?\n",
    "\n",
    "- **Predictive:** What will happen? or How can we make it happen?\n",
    "\n",
    "- **Causal:** What is the effect of doing X (explains why something happens (identifying cause-effect))?\n",
    "\n",
    "- **Optimization:** Which action leads to the best outcome?\n",
    "  -  Optimization (often prescriptive) uses these insights to find the best action to achieve a desired outcome -->\n",
    "<!-- | Decision Goal | Core Question | Purpose | Example (same scenario) |\n",
    "|---|---|---|---|\n",
    "| **Descriptive** | What happened? | Summarizes past or current state | \"Sales dropped last week.\" |\n",
    "| **Diagnostic** | Why did it happen? | Explains patterns and associations (not causal) | \"Sales dropped because shipping was slow.\" |\n",
    "| **Predictive** | What will happen next? | Forecasts future outcomes | \"If shipping stays slow, sales will continue to drop.\" |\n",
    "| **Causal** | What is the effect of doing X? | Identifies cause–effect relationships under interventions | \"Speeding up shipping increases sales.\" |\n",
    "| **Prescriptive / Optimization** | Which action leads to the best outcome? | Determines which action should be taken to achieve the best outcome | \"Between options like lowering prices or speeding up shipping, speeding up shipping improves sales the most.\" |\n",
    "\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://drive.google.com/uc?export=view&id=1gYrhseqiQKY3k1j2MgctrKFDsL-HG3SW\" width=\"450\"><br>\n",
    "  <em>Figure 2: Hierarchy of decision goals in data science and analytics.</em>\n",
    "</p>\n",
    "\n",
    "As we move from descriptive to diagnostic, predictive, causal, and finally prescriptive/optimization questions, the insights become more useful for real-world decisions, but also harder to answer. Harder questions often require: more data, stronger assumptions, better models, and sometimes experiments or interventions to identify cause and choose the best action.\n",
    "\n",
    "<!-- Optimization (often prescriptive) uses these insights to find the best action to achieve a desired outcome -->\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<!-- In data science, these questions often involve choice and **optimization**:\n",
    "\n",
    "> **Which action leads to the best outcome?** -->\n",
    "\n",
    "<!-- **What is Optimization**? Optimization is about choosing the best decision to reach a goal. Examples of goals: increase sales, reduce wait times, improve accuracy, boost conversions, etc.\n",
    "\n",
    "Formally, we define an objective $f(x)$ (something we care about) and choose the option (maximizes or minimizes $f(x)$) that performs best (according to the criteria we care about). -->\n",
    "\n",
    "\n",
    "<!-- refers to we have a goal or objective (e.g., increase conversions, reduce wait times, improve accuracy) and we want to determine which option best achieves that goal. Formally, we define an objective function $f(x)$ and select the choice $x$ that maximizes or minimizes $f(x)$ according to the criteria we care about. -->\n",
    "<!--\n",
    "For example:\n",
    "\n",
    "> “Will showing product reviews increase purchase conversions?”\n",
    "\n",
    "A tech company might test two landing pages to see which one produces a higher click-through rate (CTR). A hospital might test different rehabilitation schedules to see which one speeds recovery.  A city might test new traffic signal timings to reduce congestion.\n",
    "\n",
    "**Connecting Back to Experiments**\n",
    "\n",
    "Before we can optimize, we often need to understand causal effects (e.g., “If we change X, what happens to Y?”). This is where experiments come in.\n",
    "\n",
    "> > At this stage, the goal is not to prove anything mathematically. The goal is to clarify **what we want to learn** and **what outcome matters**. -->\n",
    "\n",
    "<!-- This question is later converted into ***testable hypotheses (null vs. alternative)*** that allow us to evaluate results. We will discuss null and alternative hypotheses *in a later chapter*. -->\n",
    "\n",
    "### **Hypotheses as Structured Guesses**\n",
    "\n",
    "A hypothesis is a **formal educated guess** about how changing an input affects an outcome:\n",
    "\n",
    "> If we increase study time, exam scores will increase.\n",
    "\n",
    "> If we reduce friction during checkout, purchases will increase.\n",
    "\n",
    "Hypotheses **do not guarantee truth**; they merely propose a relationship worth testing. Good hypotheses are directional (predict how things move), falsifiable (can be wrong), and relevant (connected to the decision at hand).\n",
    "\n",
    "In data science, hypotheses often serve a practical purpose: they tell us what data to collect and what comparisons matter.\n",
    "\n",
    "\n",
    "## **(II) Variables & Outcomes**\n",
    "\n",
    "Once we have a research question, the next step is to identify the key components of the experiment: what we **change**, what we **control**, and what we **measure**. In experimental design, these are captured through different type of variables and outcomes.\n",
    "\n",
    "\n",
    "\n",
    "**(a) Control vs. Treatment/Experiemental **\n",
    "\n",
    "An experiment typically compares:\n",
    "\n",
    "* **Control group:** receives the baseline experience\n",
    "\n",
    "* **Treatment group:** receives the new feature or intervention\n",
    "\n",
    "Differences in outcomes indicate whether the treatment has an effect.\n",
    "\n",
    "**(b) Independent vs. Dependent Variables**\n",
    "\n",
    "In experiements, we identify the variables:\n",
    "\n",
    "- What will be changed or manipulated? (**the independent variable**)\n",
    "\n",
    "- What will be measured? (**the dependent variable**)\n",
    "\n",
    "> **Example:** If a streaming service wants to see if thumbnail style affects user engagement, the thumbnail is the **independent** variable and engagement (measured as CTR, watch time, or retention) is the **dependent** variable.\n",
    "\n",
    "<center>\n",
    "  <img src=\"https://cdn.kastatic.org/ka-perseus-images/2751f1949a0954572fec1e351d1417cb401284b9.png\" width=\"450\">\n",
    "  <br>\n",
    "  <em>Figure 3. Example diagram showing a comparative setup (e.g., two groups under different conditions or phases of a study). Source: Khan Academy (cdn.kastatic.org)</em>\n",
    "</center>\n",
    "\n",
    "\n",
    "This mapping matters because a poorly defined outcome leads to wasted experimentation. If you do not know what “better” means, no experiment can tell you what to do.\n",
    "\n",
    "**(c) Metrics / Evaluation Criteria:**\n",
    "\n",
    "Experiments require measurable outcomes; such as:\n",
    "\n",
    "* Click-through rate (CTR)\n",
    "* Revenue\n",
    "* Time on task\n",
    "* Error rate\n",
    "* Completion rate\n",
    "\n",
    "Good metrics align with the decision being made. And Evaluation Criteria focus on how we quantify success (e.g., revenue per user, conversion rate, latency, retention rate).\n",
    "\n",
    "In data science, outcomes often relate to **optimization goals**. For example:\n",
    "\n",
    "- A retailer might measure **conversion rate** to see if discounts increase sales.  \n",
    "- A streaming platform might measure **watch time** to test a new recommendation algorithm.  \n",
    "- A telecom company might measure **churn rate** to evaluate a loyalty program.  \n",
    "\n",
    "Clearly defining variables and outcomes ensures that the experiment answers the original question and that results can be compared fairly across different groups.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3aDHwLq1NLWk"
   },
   "source": [
    "### Example: **A/B Testing**: The Data Science Workhorse\n",
    "\n",
    "In industry, the most widely used form of experimentation is A/B testing, where two variants (A = control, B = treatment) are compared.\n",
    "\n",
    "Examples:\n",
    "\n",
    "* Netflix tests thumbnail images\n",
    "* Amazon tests pricing or layouts\n",
    "* LinkedIn tests recommendation algorithms\n",
    "* TikTok tests ranking models\n",
    "* Meta tests news feed ranking features\n",
    "\n",
    "What makes A/B testing powerful is its simplicity and scalability, large digital platforms run thousands of concurrent experiments every year.\n",
    "\n",
    "**Practical Example:**\n",
    "\n",
    "Imagine a food delivery app wondering whether offering free delivery for first-time buyers increases conversions.\n",
    "\n",
    "* **Control:** Users see standard delivery fee.\n",
    "\n",
    "* **Treatment:** Users see free delivery offer.\n",
    "\n",
    "* **Outcome metric:** Conversion rate on first purchase.\n",
    "\n",
    "If the treatment produces a statistically significant increase, the company has evidence to roll it out widely. This logic appears almost everywhere; in UX design, pricing, logistics, healthcare, and public policy."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOL2KEd14P7TcEhJLxvd2Cw",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
