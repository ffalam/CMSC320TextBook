{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **18.2 Optimizers**\n",
        "\n",
        "Optimizers are algorithms that adjust the weights of a neural network to minimize the loss function during training. Two most basic optimizers are\n",
        " - **SGD (Stochastic Gradient Descent)**: Basic optimization\n",
        " - **Adam**: Adaptive learning rates (most popular)\n",
        "\n",
        "Stochastic Gradient Descent (SGD) updates the model’s parameters by computing the gradient of the loss on a small batch of data and moving in the direction that reduces the loss. While simple and effective, SGD uses a fixed learning rate and can be slow to converge, especially for complex models.\n",
        "\n",
        "To address these limitations, Adam (Adaptive Moment Estimation) is widely used due to its ability to adapt the learning rate for each parameter individually by combining the benefits of momentum and RMSProp optimizers. Adam often results in faster convergence and better performance without much tuning, making it the most popular choice for training deep neural networks.\n",
        "\n",
        "<sub>Note: Momentum helps speed up learning by smoothing updates using past gradients, while RMSProp adapts learning rates based on recent gradient magnitudes. Adam combines both techniques for efficient and stable training.</sub>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kn4cLQMHvj3Q"
      },
      "source": [
        "## Training Techniques & Regularization\n",
        "\n",
        "Training a neural network consists of two main steps performed repeatedly over many iterations: the **forward pass** and the **backward pass**.\n",
        "\n",
        "### Forward Pass\n",
        "\n",
        "During the forward pass, input data flows through the network, and the final output layer generates predictions $(\\hat{y}^{(i)})$ for each input example \\(i\\). The network then computes the loss function \\(L\\), which quantifies the difference between predicted outputs and true targets  $(y^{(i)}\\)$. For a batch of \\(m\\) samples, the average loss is:\n",
        "\n",
        "$$\n",
        "L = \\frac{1}{m} \\sum_{i=1}^m L\\left(\\hat{y}^{(i)}, y^{(i)}\\right)\n",
        "$$\n",
        "\n",
        "This loss guides how well the model is performing.\n",
        "\n",
        "\n",
        "Here are the details of step by step:\n",
        "\n",
        "\n",
        "## Forward Pass: Step-by-Step\n",
        "\n",
        "The forward pass is the phase in which input data flows through the neural network to produce predictions.\n",
        "\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://miro.medium.com/v2/resize:fit:1400/1*J-v2B6T9RKxdvwThtQ1NVg.png\" width=\"600\"/>\n",
        "</p>\n",
        "\n",
        "<p align=\"center\"><b>Figure: Forward Pass in Neural Networks</b></p>\n",
        "\n",
        "\n",
        "\n",
        "Here's how it works:\n",
        "\n",
        "**Input Layer**  \n",
        "Each input example is denoted as  $x_i^{(0)}$ which is fed into the network.\n",
        "\n",
        "**Hidden Layers**  \n",
        "For each hidden layer \\( l = 1, 2, \\ldots, L \\), the network performs the following steps:\n",
        "\n",
        "**Linear transformation:**  \n",
        "$$\n",
        "z_i^{[l]} = W^{[l]} x_i^{(l-1)} + b^{[l]}\n",
        "$$\n",
        "\n",
        "**Non-linear activation:**  \n",
        "$$\n",
        "x_i^{(l)} = \\sigma\\left(z_i^{[l]}\\right)\n",
        "$$  \n",
        "Here, \\( x_i^{(l)} \\) is the activated output of layer \\( l \\), used as input for the next layer.\n",
        "\n",
        "**Output Layer**  \n",
        "After the last hidden layer \\( L \\), the output layer produces the final prediction:  \n",
        "$$\n",
        "\\hat{y}_i = f\\left(x_i^{(L)}\\right)\n",
        "$$  \n",
        "where \\( f \\) is an appropriate output function (e.g., identity for regression, sigmoid for binary classification, softmax for multi-class classification).\n",
        "\n",
        "**Loss Computation**  \n",
        "\n",
        "The predicted output $\\hat{y}_i$ is compared to the true label $y_i$ using a loss function $L(\\hat{y}_i, y_i)$.\n",
        "\n",
        "Example (Mean Squared Error):  \n",
        "$$\n",
        "L(\\hat{y}_i, y_i) = (\\hat{y}_i - y_i)^2\n",
        "$$\n",
        "\n",
        "**Average Loss Over the Batch**  \n",
        "For a batch of \\( m \\) samples, the average loss is:  \n",
        "$$\n",
        "L = \\frac{1}{m} \\sum_{i=1}^m L(\\hat{y}_i, y_i)\n",
        "$$  \n",
        "This average loss quantifies how well the model is performing and is used in the backward pass to update model parameters.\n",
        "\n",
        "<h4><a href=\"/CMSC320TextBook/chapter18/interactive_forward_propagation.html\">Click Here for Interactive Forward Propagation Visualization</a></h4>\n",
        "\n",
        "## Backward Pass (Backpropagation)\n",
        "\n",
        "In the backward pass, gradients of the loss with respect to each parameter (weights $W^{[l]}$ at layer $l$) are computed using the chain rule.\n",
        "\n",
        "The chain rule lets us break down the gradient of the loss into simpler parts by following the flow of computations backward through the network. It helps calculate how changes in weights affect the final loss by multiplying the derivatives of each intermediate step.\n",
        "\n",
        "Mathematically:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial L}{\\partial W^{[l]}} =\n",
        "\\frac{\\partial L}{\\partial a^{[l]}} \\cdot\n",
        "\\frac{\\partial a^{[l]}}{\\partial z^{[l]}} \\cdot\n",
        "\\frac{\\partial z^{[l]}}{\\partial W^{[l]}}\n",
        "$$\n",
        "\n",
        "where:\n",
        "\n",
        "- $a^{[l]}$ is the activation output of layer $l$,  \n",
        "- $z^{[l]} = W^{[l]} a^{[l-1]} + b^{[l]}$ is the input to the activation function.\n",
        "\n",
        "**Weight Update**  \n",
        "The weights are then updated using gradient descent:\n",
        "\n",
        "$$\n",
        "W^{[l]} := W^{[l]} - \\alpha \\cdot \\frac{\\partial L}{\\partial W^{[l]}}\n",
        "$$\n",
        "\n",
        "where:\n",
        "\n",
        "- $W^{[l]}$ = current weights at layer $l$,  \n",
        "- $\\alpha$ = learning rate (controls the step size),  \n",
        "- $\\frac{\\partial L}{\\partial W^{[l]}}$ = gradient of the loss with respect to the weights.\n",
        "\n",
        "**Repeat**  \n",
        "This process of forward pass, backward pass, and weight update is repeated over many epochs (full passes over the training data) until the error is minimized.\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://miro.medium.com/v2/resize:fit:1400/0*LnQvzEdc8wkkUte9.png\" width=\"600\"/>\n",
        "</p>\n",
        "\n",
        "<p align=\"center\"><b>Figure: Backpropagation in Neural Networks</b></p>\n",
        "\n",
        "<h4><a href=\"/CMSC320TextBook/chapter18/interactive_backward_propagation.html\">Click Here for Interactive Backpropagation Visualization</a></h4>\n",
        "\n",
        "<!--\n",
        "### Backward Pass (Backpropagation)\n",
        "\n",
        "In the backward pass, gradients of the loss with respect to each parameter (weights \\(W^{[l]}\\) at layer \\(l\\)) are computed using the **chain rule**:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial L}{\\partial W^{[l]}} = \\frac{\\partial L}{\\partial a^{[l]}} \\cdot \\frac{\\partial a^{[l]}}{\\partial z^{[l]}} \\cdot \\frac{\\partial z^{[l]}}{\\partial W^{[l]}}\n",
        "$$\n",
        "Where:  \n",
        "- $a^{[l]}$ is the activation output of layer $l$,  \n",
        "- $z^{[l]}$ is the linear combination $W^{[l]} a^{[l-1]} + b^{[l]}$.\n",
        "\n",
        "\n",
        "Parameters are updated using gradient descent with learning rate \\(\\alpha\\):\n",
        "\n",
        "$$\n",
        "W^{[l]} := W^{[l]} - \\alpha \\frac{\\partial L}{\\partial W^{[l]}}\n",
        "$$\n",
        "\n",
        "# Backward Pass (Error Propagation)\n",
        "\n",
        "After computing the loss, the error is sent backward through the network to find out how much each weight contributed to the error.\n",
        "\n",
        "Using the chain rule, the network calculates the gradient of the loss with respect to each weight — this tells us the direction and amount to change the weights to reduce the error.\n",
        "\n",
        "**Weight Update**  \n",
        "The weights are then updated using gradient descent:\n",
        "\n",
        "$$\n",
        "W := W - \\eta \\cdot \\frac{\\partial L}{\\partial W}\n",
        "$$\n",
        "\n",
        "where:\n",
        "\n",
        "- $W$ = current weights  \n",
        "- $\\eta$ = learning rate (controls how big each update is)  \n",
        "- $\\frac{\\partial L}{\\partial W}$ = gradient of loss w.r.t. weights  \n",
        "\n",
        "**Repeat**  \n",
        "This process of forward pass, backward pass, and weight update repeats over many epochs (full passes over the training data) until the error becomes small enough. -->\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<!-- ### Regularization Techniques\n",
        "\n",
        "Regularization adds penalty terms to the loss function to prevent overfitting by constraining model complexity:\n",
        "\n",
        "- **L2 Regularization (Weight Decay):**\n",
        "\n",
        "$$\n",
        "L_{\\text{reg}} = L + \\lambda \\sum \\|W\\|_2^2\n",
        "$$\n",
        "\n",
        "- **L1 Regularization:**\n",
        "\n",
        "$$\n",
        "L_{\\text{reg}} = L + \\lambda \\sum |W|\n",
        "$$\n",
        "\n",
        "Where $\\lambda$ controls the regularization strength.\n",
        "\n",
        "\n",
        "Adding these terms encourages smaller or sparser weights, improving generalization on unseen data. -->\n",
        "\n",
        "## Regularization Techniques\n",
        "\n",
        "Regularization adds penalty terms to the loss function to prevent overfitting, which happens when the model learns the training data too well including noise, resulting in poor performance on new, unseen data. By constraining model complexity, regularization encourages the model to generalize better.\n",
        "\n",
        "---\n",
        "\n",
        "### L2 Regularization (Weight Decay):\n",
        "\n",
        "$$\n",
        "L_{reg} = L + \\lambda \\sum \\| W \\|_2^2 = L + \\lambda \\sum W^2\n",
        "$$\n",
        "\n",
        "L2 regularization adds the sum of the squared weights to the loss function. The hyperparameter $\\lambda$ controls the strength of this penalty. This encourages the model to keep weights small but not necessarily zero, which tends to distribute the \"importance\" across many features and reduces overfitting.\n",
        "\n",
        "---\n",
        "\n",
        "### L1 Regularization:\n",
        "\n",
        "$$\n",
        "L_{reg} = L + \\lambda \\sum |W|\n",
        "$$\n",
        "\n",
        "L1 regularization adds the sum of the absolute values of the weights to the loss. This tends to push some weights exactly to zero, effectively performing feature selection by encouraging sparsity in the model. This can be useful when you want a simpler model with fewer active features.\n",
        "\n",
        "---\n",
        "\n",
        "### Why Use Regularization?\n",
        "\n",
        "- **Improves Generalization:** By limiting the size or number of weights, the model avoids fitting noise and irrelevant patterns in the training data.  \n",
        "- **Controls Model Complexity:** Prevents weights from growing too large, which can cause unstable predictions.  \n",
        "- **Feature Selection (L1):** Helps identify and ignore irrelevant features by forcing their weights to zero.\n",
        "\n",
        "---\n",
        "\n",
        "### Choosing $\\lambda$\n",
        "\n",
        "The regularization strength $\\lambda$ is a hyperparameter that must be tuned carefully:\n",
        "\n",
        "- Too small: little effect on overfitting  \n",
        "- Too large: model may underfit by being too constrained\n",
        "\n",
        "---\n",
        "\n",
        "### Example: When to Use L1 vs. L2 Regularization\n",
        "\n",
        "- **L2 Regularization (Ridge):**  \n",
        "Use when most features are relevant and you want to keep them all but reduce overfitting by shrinking weights smoothly.  \n",
        "*Example:* Predicting house prices using many meaningful features.\n",
        "\n",
        "- **L1 Regularization (Lasso):**  \n",
        "Use when you expect only a few important features and want the model to ignore irrelevant ones by setting some weights exactly to zero.  \n",
        "*Example:* Selecting important genes from thousands of candidates in a biological study.\n",
        "\n",
        "---\n",
        "\n",
        "### Other Common Regularization Methods (Brief)\n",
        "\n",
        "- **Dropout:** Randomly sets some activations to zero during training to prevent co-adaptation of neurons, helping the model generalize better.  \n",
        "- **Early Stopping:** Stops training when performance on a validation set stops improving, preventing overfitting.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaC2y5rYGfCz"
      },
      "source": [
        "## Putting It All Together: How Neural Network Training Happens\n",
        "\n",
        "After understanding how regularization helps prevent overfitting and improve generalization, it's important to see how the entire training process operates in practice. Training a neural network involves repeatedly feeding data through the model in manageable portions, updating parameters, and gradually improving performance.\n",
        "\n",
        "The next section explains the key concepts of **batch size**, **iteration**, and **epoch**, which organize how training data is processed and how the model learns over time.\n",
        "\n",
        "---\n",
        "\n",
        "## Neural Network Training: Batch Size, Iteration, and Epoch\n",
        "\n",
        "When training a neural network, the dataset is usually too large to process all at once, so it is split into smaller parts called **batches**.\n",
        "\n",
        "---\n",
        "\n",
        "### Batch Size  \n",
        "The number of training examples used in one forward and backward pass.  \n",
        "For example, a batch size of 32 means the model processes 32 samples before updating weights.\n",
        "\n",
        "---\n",
        "\n",
        "### Iteration  \n",
        "One update of the model’s parameters (weights and biases).  \n",
        "Each iteration uses one batch of data.\n",
        "\n",
        "---\n",
        "\n",
        "### Epoch  \n",
        "One full pass over the entire training dataset.  \n",
        "If the dataset has 1000 samples and batch size is 100, then:  \n",
        "$$\n",
        "1 \\text{ epoch} = \\frac{1000}{100} = 10 \\text{ iterations}\n",
        "$$\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media.geeksforgeeks.org/wp-content/uploads/20241024155237307614/epoch-in-machine-learning_.webp\" width=\"600\"/>\n",
        "</p>\n",
        "\n",
        "<p align=\"center\"><b>Figure: Epoch in Machine Learning</b></p>\n",
        "\n",
        "---\n",
        "\n",
        "### Training Process Overview\n",
        "\n",
        "1. **Start Training:** Initialize model parameters.\n",
        "\n",
        "2. For each epoch (repeat multiple times):\n",
        "\n",
        "   - Divide data into batches according to batch size.  \n",
        "   \n",
        "   - For each batch:  \n",
        "     - Perform forward pass to calculate predictions.  \n",
        "     - Calculate loss based on predictions and true labels.  \n",
        "     - Perform backward pass (backpropagation) to compute gradients.  \n",
        "     - Update weights using gradients (e.g., gradient descent).\n",
        "\n",
        "\n",
        "3. Repeat until model performance stabilizes or desired accuracy is reached.\n",
        "\n",
        "\n",
        "<p>\n",
        "  <img src=\"https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TFKm_XC2dIk36i80drQ0KA.png\" width=\"600\"/>\n",
        "</p>\n",
        "\n",
        "<p>\n",
        "  <b>Figure:</b> In the Input Training Dataset step, as different kinds of strategies, we can assign a Batch Size to determine how many training datasets are going to be used for one weights updating process. For example, there are 5000 images in total as the training datasets. If we set the Batch Size = 1000, we get 5 batches of training datasets. As a result, the weights updating process will be executed 5 times (Iterations).\n",
        "</p>\n",
        "\n",
        "<p><em>Ref: <a href=\"https://medium.com/@crazyhatcap/epoch-batch-size-iteration-in-neural-network-training-process-bee58415eb8e\" target=\"_blank\">medium.com/@crazyhatcap</a></em></p>"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
