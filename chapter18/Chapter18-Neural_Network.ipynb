{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 18: Introduction to the  Neural Network\n",
        "\n",
        "\n",
        "Artificial intelligence has revolutionized the way machines learn from data, enabling them to perform tasks that once seemed impossible. From powering voice assistants to enabling autonomous vehicles, AI systems are now integrated into many aspects of daily life. At the core of this transformation are neural networks—computational models inspired by **the structure and function of the human brain**. These networks consist of interconnected nodes, or \"neurons,\" that process information in layers, allowing them to recognize patterns, make decisions, and improve over time. From early single-layer perceptrons to today’s deep architectures, neural networks have become a cornerstone of modern AI, powering breakthroughs in fields like healthcare, finance, and autonomous systems.\n",
        "\n",
        "> Neural networks are a **type of supervised learning algorithm** capable of identifying intricate patterns and relationships within data, making them suitable for tackling problems that traditional models often struggle with.\n",
        "\n",
        "![NN](imgs/NN.png)\n",
        "\n",
        "\n",
        "Although neural network algorithms have existed for many years, recent advancements in their architectures have led to significant improvements in performance on large-scale machine learning tasks. These developments form the foundation of what is now referred to as the \"deep learning\" methodology.\n",
        "\n",
        "Deep learning, a branch of machine learning and artificial intelligence, leverages neural networks with multiple hidden layers to address highly complex tasks. These tasks range from natural language processing—such as speech recognition and text interpretation—to computer vision applications like object detection and image classification. The rise of deep learning over the past twenty years can be attributed to its remarkable effectiveness, the surge in computational power, and the growing accessibility of vast datasets."
      ],
      "metadata": {
        "id": "vG0Z1u8yTPRI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 18.1 Fundamentals of Neural Networks\n",
        "\n",
        "Neural networks are a powerful class of supervised learning algorithms capable of modeling complex, nonlinear relationships in data. Unlike traditional machine learning models, which rely on handcrafted features, neural networks automatically learn hierarchical representations from raw input. Key components include:\n",
        "\n",
        "* **Input Layer:** Receives raw data (e.g., pixels in an image, words in a text).\n",
        "\n",
        "* **Hidden Layers:** Intermediate layers that transform inputs through weighted connections and activation functions.\n",
        "\n",
        "* **Output Layer:** Produces the final prediction (e.g., class label, regression value).\n",
        "\n",
        "* **Weights & Biases:** Adjustable parameters learned during training.\n",
        "\n",
        "* **Activation Functions:** Introduce nonlinearity (e.g., ReLU, Sigmoid, Tanh).\n",
        "\n",
        "COMMENT: WE CAN ADD SOME GIF VISUALIZATION of Neural Network HERE: input later to hidden output\n",
        "\n",
        "Training a neural network involves **forward propagation** (passing data through the network) and **backpropagation **(adjusting weights based on error gradients using optimization techniques like gradient descent)."
      ],
      "metadata": {
        "id": "Z2Ta9SqhT8lu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **18.1 Neurons: The Building Blocks**\n",
        "\n",
        "A neuron (or node) is the fundamental unit of a neural network, mimicking biological neurons. It receives inputs, processes them using weights and an activation function, and produces an output. Mathematically, a neuron's operation can be represented as:\n",
        "\n",
        "\n",
        "$$ y = f\\left(\\sum_{i=1}^{n} (w_i x_i) + b\\right) $$\n",
        "\n",
        "Where:\n",
        "- $x_i$ = input features\n",
        "- $w_i$ = weights\n",
        "- $b$ = bias term  \n",
        "- $f$ = activation function\n",
        "\n",
        "\n",
        "## **4.2.2 Layers: Input, Hidden, and Output**\n",
        "Neural networks are organized into layers:\n",
        "\n",
        "1. **Input Layer**:\n",
        "    - The first layer that receives raw data (e.g., pixel values in an image, word embeddings in text).\n",
        "\n",
        "2. **Hidden Layers**:\n",
        "    - Intermediate layers between input and output where feature extraction and transformation occur.\n",
        "    - Deep networks have multiple hidden layers\n",
        "\n",
        " 3. **Output Layer**:\n",
        "    - Produces final predictions\n",
        "    - Classification: class probabilities\n",
        "    - Regression: continuous values\n",
        "\n",
        "\n",
        "## **18.3 Weights and Biases**\n",
        " | Component | Role |\n",
        " |-----------|------|\n",
        " | **Weights** (\\( w_i \\)) | Determine connection strength between neurons. They are adjusted during training to minimize prediction errors. |\n",
        "  | **Bias** (\\( b \\)) | Allows shifting the activation function to improve model flexibility. |\n",
        "\n",
        "\n",
        "\n",
        "## **18.4 Activation Functions**\n",
        "\n",
        "Activation functions are essential components of neural networks, introducing non-linearities that enable the model to learn complex patterns. Without them, a neural network would simply be a linear regression model, incapable of handling intricate data relationships. This section explores four widely used activation functions: Sigmoid, ReLU, Tanh, and Softmax, discussing their properties, advantages, and limitations. Each has unique properties and use cases depending on the architecture and goal of the model.\n",
        "\n",
        "\n",
        "| Function  | Formula                          | Use Case                      |\n",
        "|-----------|----------------------------------|-------------------------------|\n",
        "| **Sigmoid** | $\\sigma(x) = \\frac{1}{1 + e^{-x}}$ | Binary classification  (outputs between 0 and 1)         |\n",
        "| **ReLU**   | $f(x) = \\max(0, x)$              | Default choice for hidden layers (fast computation)    |\n",
        "| **Tanh**   | $\\tanh(x) = \\frac{e^x - e^{-x}}{e^x + e^{-x}}$ | Similar to sigmoid but outputs between -1 and 1 |\n",
        "| **Softmax**| $\\sigma(z)_i = \\frac{e^{z_i}}{\\sum_{j=1}^K e^{z_j}}$ | Multi-class classification (outputs probabilities) |\n",
        "\n",
        "\n",
        "**The sigmoid function:**  maps any real-valued number to a range between 0 and 1, making it suitable for binary classification tasks where outputs represent probabilities.\n",
        "This function $\\sigma(x) = \\frac{1}{1 + e^{-x}}$  maps any real-valued input into a probability-like output, making it useful in binary classification and output layers where probabilistic interpretation is needed.\n",
        "\n",
        "Advantages:\n",
        "* Useful when outputs need to be interpreted as probabilities.\n",
        "*Differentiable, allowing gradient-based optimization.\n",
        "\n",
        "\n",
        "Disadvantages:\n",
        "* Vanishing Gradients: For very large or small inputs, gradients become nearly zero, slowing down learning.\n",
        "* Not Zero-Centered: Outputs are always positive, leading to inefficient weight updates\n",
        "* Computationally Expensive: Involves exponentiation operations.\n",
        "\n",
        "\n",
        "**ReLU (Rectified Linear Unit) Function:** is one of the most popular activation functions due to its simplicity and effectiveness. It outputs the input directly if positive; otherwise, it outputs zero ($f(x) = \\max(0, x)$). It is non-linear but simple; computationally efficient.\n",
        "\n",
        "Advantages:\n",
        "\n",
        "* Avoids Vanishing Gradient (for positive inputs): Unlike sigmoid, gradients remain strong for active neurons.\n",
        "* Fast Computation: No complex exponentials.\n",
        "* Sparsity: Can deactivate neurons (output zero), making the network more efficient.\n",
        "\n",
        "Disadvantages:\n",
        "\n",
        "* Dying ReLU Problem: If many neurons output zero (due to negative inputs), they stop learning entirely.\n",
        "*\n",
        "Not Zero-Centered: Like sigmoid, can lead to slower convergence.\n",
        "\n",
        "What is the **Dying ReLU** Problem?\n",
        "If a neuron consistently receives negative inputs, its output becomes zero, and its weights stop updating (since the gradient is also zero). Over time, this can cause some neurons to \"die\" and never activate again, reducing the model’s capacity to learn (neurons stop contributing to learning).\n",
        "\n",
        "Solutions to Dying ReLU:\n",
        "\n",
        "* Leaky ReLU: Allows a small negative slope (e.g., 0.01) for negative inputs.\n",
        "$$\n",
        "\\text{Leaky ReLU}(x) =\n",
        "\\begin{cases}\n",
        "x, & \\text{if } x \\geq 0 \\\\\n",
        "\\alpha x, & \\text{if } x < 0\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "where $\\alpha$ is a small positive constant (e.g., 0.01).\n",
        "\n",
        "* Parametric ReLU (PReLU): Learns the negative slope during training.\n",
        "\n",
        "* Exponential Linear Unit (ELU): Smoothly handles negative inputs.\n",
        "\n",
        "**Tanh (Hyperbolic Tangent) Function:**\n",
        "The tanh function is similar to sigmoid but maps inputs to a range between -1 and 1, making it zero-centered, $\\tanh(x) = \\frac{e^x - e^{-x}}{e^x + e^{-x}}$.\n",
        "* In neural networks, an activation function is zero-centered if its output values are symmetrically distributed around zero (i.e., they have a mean of zero). This property helps in maintaining stable and efficient training by preventing systematic weight updates in a single direction.\n",
        "\n",
        "* When activation outputs are not zero-centered (e.g., sigmoid outputs between 0 and 1), gradients during backpropagation tend to be either all positive or all negative, leading to inefficient weight updates: tend to update in the same direction (either always increasing or always decreasing), slowing down convergence.\n",
        "\n",
        "Advantages:\n",
        "\n",
        "* Zero-centered output allows for better convergence during gradient descent.\n",
        "\n",
        "* Stronger gradients than sigmoid for inputs near 0.\n",
        "\n",
        "Disadvantages:\n",
        "\n",
        "* Still suffers from the vanishing gradient problem for very large or very small inputs:: Like sigmoid, gradients become very small for extreme values.\n",
        "\n",
        "* Slightly More Computationally Expensive: Due to exponential operations.\n",
        "\n",
        "**The Softmax function** is typically used in the output layer of a multi-class classification model. It converts a vector of raw scores (logits) into a probability distribution over predicted output classes: **Softmax**| $\\sigma(z)_i = \\frac{e^{z_i}}{\\sum_{j=1}^K e^{z_j}}$.\n",
        "\n",
        "\n",
        "Advantages:\n",
        "\n",
        "* Ensures that the sum of the outputs is 1, making them interpretable as probabilities.\n",
        "\n",
        "* Highlights the highest-valued input while suppressing the rest, which helps in clear class predictions.\n",
        "\n",
        "Disadvantages:\n",
        "\n",
        "* Exponentially sensitive to input scale—can cause numerical instability if logits are too large.\n",
        "\n",
        "* When classes are not mutually exclusive, Softmax is not ideal (use sigmoid instead for multi-label classification).\n",
        "\n",
        "<h4><a href=\"/CMSC320TextBook/chapter18/interactive_activation_functions.html\">Click Here for Interactive Activation Function Visualization</a></h4>\n",
        "\n",
        "## **4.2.5 Loss Functions**\n",
        "Loss functions (or cost functions) measure how well a neural network’s predictions match the true target values. During training, the goal is to minimize the loss by adjusting the model’s parameters. The choice of loss function depends on the type of task:\n",
        "\n",
        "\n",
        "\n",
        " - **Mean Squared Error (MSE)**: is widely used in regression problems, such as predicting house prices or temperature, where the  output is continuous and goal is to minimize the average squared difference between predicted and actual values.$$L_{MSE} = \\frac{1}{N}\\sum_{i=1}^N (y_i - \\hat{y}_i)^2$$\n",
        "\n",
        " As it calculates the average squared difference between predicted values and actual values, which means larger errors are penalized more heavily. While MSE is straightforward and differentiable, making it compatible with gradient descent, it has notable drawbacks: it is highly sensitive to outliers due to the squaring operation, and it performs poorly in classification tasks, often leading to slow convergence.\n",
        "\n",
        " - **Cross-Entropy Loss**: On the other hand, Cross-Entropy Loss is widely used for classification tasks, both binary and multi-class. It measures the difference between the predicted probability distribution and the true label distribution.\n",
        "- For binary classification:\n",
        "\n",
        "$$L_{BCE} = -\\frac{1}{N}\\sum_{i=1}^N \\left[y_i\\log(\\hat{y}_i) + (1-y_i)\\log(1-\\hat{y}_i)\\right]$$\n",
        "-   - For multi-class classification:\n",
        "\n",
        "$$L_{CCE} = -\\frac{1}{N}\\sum_{i=1}^N \\sum_{c=1}^C y_{i,c}\\log(\\hat{y}_{i,c})$$\n",
        "\n",
        " For binary classification, it penalizes the model when it confidently predicts the wrong class, encouraging outputs closer to the true labels. In multi-class settings, cross-entropy works with softmax outputs to handle multiple classes simultaneously. One disadvantage of cross-entropy loss is that it can become very large when the model assigns near-zero probabilities to the true class, which may cause instability during training if not handled properly.\n",
        "\n",
        "\n",
        "## **4.2.6 Optimizers**\n",
        "\n",
        "Optimizers are algorithms that adjust the weights of a neural network to minimize the loss function during training. Two most basic optimizers are\n",
        " - **SGD (Stochastic Gradient Descent)**: Basic optimization\n",
        " - **Adam**: Adaptive learning rates (most popular)\n",
        "\n",
        "Stochastic Gradient Descent (SGD) updates the model’s parameters by computing the gradient of the loss on a small batch of data and moving in the direction that reduces the loss. While simple and effective, SGD uses a fixed learning rate and can be slow to converge, especially for complex models.\n",
        "\n",
        "To address these limitations, Adam (Adaptive Moment Estimation) is widely used due to its ability to adapt the learning rate for each parameter individually by combining the benefits of momentum and RMSProp optimizers. Adam often results in faster convergence and better performance without much tuning, making it the most popular choice for training deep neural networks.\n",
        "\n",
        "<sub>Note: Momentum helps speed up learning by smoothing updates using past gradients, while RMSProp adapts learning rates based on recent gradient magnitudes. Adam combines both techniques for efficient and stable training.</sub>\n",
        "\n",
        "## 4.2.7 Training Techniques & Regularization\n",
        "\n",
        "Training a neural network consists of two main steps performed repeatedly over many iterations: the **forward pass** and the **backward pass**.\n",
        "\n",
        "### Forward Pass\n",
        "\n",
        "During the forward pass, input data flows through the network, and the final output layer generates predictions $(\\hat{y}^{(i)})$ for each input example \\(i\\). The network then computes the loss function \\(L\\), which quantifies the difference between predicted outputs and true targets  $(y^{(i)}\\)$. For a batch of \\(m\\) samples, the average loss is:\n",
        "\n",
        "$$\n",
        "L = \\frac{1}{m} \\sum_{i=1}^m L\\left(\\hat{y}^{(i)}, y^{(i)}\\right)\n",
        "$$\n",
        "\n",
        "This loss guides how well the model is performing.\n",
        "\n",
        "\n",
        "Here are the details of step by step:\n",
        "\n",
        "\n",
        "## Forward Pass: Step-by-Step\n",
        "\n",
        "The forward pass is the phase in which input data flows through the neural network to produce predictions.\n",
        "\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://miro.medium.com/v2/resize:fit:1400/1*J-v2B6T9RKxdvwThtQ1NVg.png\" width=\"600\"/>\n",
        "</p>\n",
        "\n",
        "<p align=\"center\"><b>Figure: Forward Pass in Neural Networks</b></p>\n",
        "\n",
        "\n",
        "\n",
        "Here's how it works:\n",
        "\n",
        "**Input Layer**  \n",
        "Each input example is denoted as  $x_i^{(0)}$ which is fed into the network.\n",
        "\n",
        "**Hidden Layers**  \n",
        "For each hidden layer \\( l = 1, 2, \\ldots, L \\), the network performs the following steps:\n",
        "\n",
        "**Linear transformation:**  \n",
        "$$\n",
        "z_i^{[l]} = W^{[l]} x_i^{(l-1)} + b^{[l]}\n",
        "$$\n",
        "\n",
        "**Non-linear activation:**  \n",
        "$$\n",
        "x_i^{(l)} = \\sigma\\left(z_i^{[l]}\\right)\n",
        "$$  \n",
        "Here, \\( x_i^{(l)} \\) is the activated output of layer \\( l \\), used as input for the next layer.\n",
        "\n",
        "**Output Layer**  \n",
        "After the last hidden layer \\( L \\), the output layer produces the final prediction:  \n",
        "$$\n",
        "\\hat{y}_i = f\\left(x_i^{(L)}\\right)\n",
        "$$  \n",
        "where \\( f \\) is an appropriate output function (e.g., identity for regression, sigmoid for binary classification, softmax for multi-class classification).\n",
        "\n",
        "**Loss Computation**  \n",
        "\n",
        "The predicted output $\\hat{y}_i$ is compared to the true label $y_i$ using a loss function $L(\\hat{y}_i, y_i)$.\n",
        "\n",
        "Example (Mean Squared Error):  \n",
        "$$\n",
        "L(\\hat{y}_i, y_i) = (\\hat{y}_i - y_i)^2\n",
        "$$\n",
        "\n",
        "**Average Loss Over the Batch**  \n",
        "For a batch of \\( m \\) samples, the average loss is:  \n",
        "$$\n",
        "L = \\frac{1}{m} \\sum_{i=1}^m L(\\hat{y}_i, y_i)\n",
        "$$  \n",
        "This average loss quantifies how well the model is performing and is used in the backward pass to update model parameters.\n",
        "\n",
        "<h4><a href=\"/CMSC320TextBook/chapter18/interactive_forward_propagation.html\">Click Here for Interactive Forward Propagation Visualization</a></h4>\n",
        "\n",
        "## Backward Pass (Backpropagation)\n",
        "\n",
        "In the backward pass, gradients of the loss with respect to each parameter (weights $W^{[l]}$ at layer $l$) are computed using the chain rule.\n",
        "\n",
        "The chain rule lets us break down the gradient of the loss into simpler parts by following the flow of computations backward through the network. It helps calculate how changes in weights affect the final loss by multiplying the derivatives of each intermediate step.\n",
        "\n",
        "Mathematically:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial L}{\\partial W^{[l]}} =\n",
        "\\frac{\\partial L}{\\partial a^{[l]}} \\cdot\n",
        "\\frac{\\partial a^{[l]}}{\\partial z^{[l]}} \\cdot\n",
        "\\frac{\\partial z^{[l]}}{\\partial W^{[l]}}\n",
        "$$\n",
        "\n",
        "where:\n",
        "\n",
        "- $a^{[l]}$ is the activation output of layer $l$,  \n",
        "- $z^{[l]} = W^{[l]} a^{[l-1]} + b^{[l]}$ is the input to the activation function.\n",
        "\n",
        "**Weight Update**  \n",
        "The weights are then updated using gradient descent:\n",
        "\n",
        "$$\n",
        "W^{[l]} := W^{[l]} - \\alpha \\cdot \\frac{\\partial L}{\\partial W^{[l]}}\n",
        "$$\n",
        "\n",
        "where:\n",
        "\n",
        "- $W^{[l]}$ = current weights at layer $l$,  \n",
        "- $\\alpha$ = learning rate (controls the step size),  \n",
        "- $\\frac{\\partial L}{\\partial W^{[l]}}$ = gradient of the loss with respect to the weights.\n",
        "\n",
        "**Repeat**  \n",
        "This process of forward pass, backward pass, and weight update is repeated over many epochs (full passes over the training data) until the error is minimized.\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://miro.medium.com/v2/resize:fit:1400/0*LnQvzEdc8wkkUte9.png\" width=\"600\"/>\n",
        "</p>\n",
        "\n",
        "<p align=\"center\"><b>Figure: Backpropagation in Neural Networks</b></p>\n",
        "\n",
        "<h4><a href=\"/CMSC320TextBook/chapter18/interactive_backward_propagation.html\">Click Here for Interactive Backpropagation Visualization</a></h4>\n",
        "\n",
        "<!--\n",
        "### Backward Pass (Backpropagation)\n",
        "\n",
        "In the backward pass, gradients of the loss with respect to each parameter (weights \\(W^{[l]}\\) at layer \\(l\\)) are computed using the **chain rule**:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial L}{\\partial W^{[l]}} = \\frac{\\partial L}{\\partial a^{[l]}} \\cdot \\frac{\\partial a^{[l]}}{\\partial z^{[l]}} \\cdot \\frac{\\partial z^{[l]}}{\\partial W^{[l]}}\n",
        "$$\n",
        "Where:  \n",
        "- $a^{[l]}$ is the activation output of layer $l$,  \n",
        "- $z^{[l]}$ is the linear combination $W^{[l]} a^{[l-1]} + b^{[l]}$.\n",
        "\n",
        "\n",
        "Parameters are updated using gradient descent with learning rate \\(\\alpha\\):\n",
        "\n",
        "$$\n",
        "W^{[l]} := W^{[l]} - \\alpha \\frac{\\partial L}{\\partial W^{[l]}}\n",
        "$$\n",
        "\n",
        "# Backward Pass (Error Propagation)\n",
        "\n",
        "After computing the loss, the error is sent backward through the network to find out how much each weight contributed to the error.\n",
        "\n",
        "Using the chain rule, the network calculates the gradient of the loss with respect to each weight — this tells us the direction and amount to change the weights to reduce the error.\n",
        "\n",
        "**Weight Update**  \n",
        "The weights are then updated using gradient descent:\n",
        "\n",
        "$$\n",
        "W := W - \\eta \\cdot \\frac{\\partial L}{\\partial W}\n",
        "$$\n",
        "\n",
        "where:\n",
        "\n",
        "- $W$ = current weights  \n",
        "- $\\eta$ = learning rate (controls how big each update is)  \n",
        "- $\\frac{\\partial L}{\\partial W}$ = gradient of loss w.r.t. weights  \n",
        "\n",
        "**Repeat**  \n",
        "This process of forward pass, backward pass, and weight update repeats over many epochs (full passes over the training data) until the error becomes small enough. -->\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<!-- ### Regularization Techniques\n",
        "\n",
        "Regularization adds penalty terms to the loss function to prevent overfitting by constraining model complexity:\n",
        "\n",
        "- **L2 Regularization (Weight Decay):**\n",
        "\n",
        "$$\n",
        "L_{\\text{reg}} = L + \\lambda \\sum \\|W\\|_2^2\n",
        "$$\n",
        "\n",
        "- **L1 Regularization:**\n",
        "\n",
        "$$\n",
        "L_{\\text{reg}} = L + \\lambda \\sum |W|\n",
        "$$\n",
        "\n",
        "Where $\\lambda$ controls the regularization strength.\n",
        "\n",
        "\n",
        "Adding these terms encourages smaller or sparser weights, improving generalization on unseen data. -->\n",
        "\n",
        "## Regularization Techniques\n",
        "\n",
        "Regularization adds penalty terms to the loss function to prevent overfitting, which happens when the model learns the training data too well including noise, resulting in poor performance on new, unseen data. By constraining model complexity, regularization encourages the model to generalize better.\n",
        "\n",
        "---\n",
        "\n",
        "### L2 Regularization (Weight Decay):\n",
        "\n",
        "$$\n",
        "L_{reg} = L + \\lambda \\sum \\| W \\|_2^2 = L + \\lambda \\sum W^2\n",
        "$$\n",
        "\n",
        "L2 regularization adds the sum of the squared weights to the loss function. The hyperparameter $\\lambda$ controls the strength of this penalty. This encourages the model to keep weights small but not necessarily zero, which tends to distribute the \"importance\" across many features and reduces overfitting.\n",
        "\n",
        "---\n",
        "\n",
        "### L1 Regularization:\n",
        "\n",
        "$$\n",
        "L_{reg} = L + \\lambda \\sum |W|\n",
        "$$\n",
        "\n",
        "L1 regularization adds the sum of the absolute values of the weights to the loss. This tends to push some weights exactly to zero, effectively performing feature selection by encouraging sparsity in the model. This can be useful when you want a simpler model with fewer active features.\n",
        "\n",
        "---\n",
        "\n",
        "### Why Use Regularization?\n",
        "\n",
        "- **Improves Generalization:** By limiting the size or number of weights, the model avoids fitting noise and irrelevant patterns in the training data.  \n",
        "- **Controls Model Complexity:** Prevents weights from growing too large, which can cause unstable predictions.  \n",
        "- **Feature Selection (L1):** Helps identify and ignore irrelevant features by forcing their weights to zero.\n",
        "\n",
        "---\n",
        "\n",
        "### Choosing $\\lambda$\n",
        "\n",
        "The regularization strength $\\lambda$ is a hyperparameter that must be tuned carefully:\n",
        "\n",
        "- Too small: little effect on overfitting  \n",
        "- Too large: model may underfit by being too constrained\n",
        "\n",
        "---\n",
        "\n",
        "### Example: When to Use L1 vs. L2 Regularization\n",
        "\n",
        "- **L2 Regularization (Ridge):**  \n",
        "Use when most features are relevant and you want to keep them all but reduce overfitting by shrinking weights smoothly.  \n",
        "*Example:* Predicting house prices using many meaningful features.\n",
        "\n",
        "- **L1 Regularization (Lasso):**  \n",
        "Use when you expect only a few important features and want the model to ignore irrelevant ones by setting some weights exactly to zero.  \n",
        "*Example:* Selecting important genes from thousands of candidates in a biological study.\n",
        "\n",
        "---\n",
        "\n",
        "### Other Common Regularization Methods (Brief)\n",
        "\n",
        "- **Dropout:** Randomly sets some activations to zero during training to prevent co-adaptation of neurons, helping the model generalize better.  \n",
        "- **Early Stopping:** Stops training when performance on a validation set stops improving, preventing overfitting.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Kn4cLQMHvj3Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Putting It All Together: How Neural Network Training Happens\n",
        "\n",
        "After understanding how regularization helps prevent overfitting and improve generalization, it's important to see how the entire training process operates in practice. Training a neural network involves repeatedly feeding data through the model in manageable portions, updating parameters, and gradually improving performance.\n",
        "\n",
        "The next section explains the key concepts of **batch size**, **iteration**, and **epoch**, which organize how training data is processed and how the model learns over time.\n",
        "\n",
        "---\n",
        "\n",
        "## Neural Network Training: Batch Size, Iteration, and Epoch\n",
        "\n",
        "When training a neural network, the dataset is usually too large to process all at once, so it is split into smaller parts called **batches**.\n",
        "\n",
        "---\n",
        "\n",
        "### Batch Size  \n",
        "The number of training examples used in one forward and backward pass.  \n",
        "For example, a batch size of 32 means the model processes 32 samples before updating weights.\n",
        "\n",
        "---\n",
        "\n",
        "### Iteration  \n",
        "One update of the model’s parameters (weights and biases).  \n",
        "Each iteration uses one batch of data.\n",
        "\n",
        "---\n",
        "\n",
        "### Epoch  \n",
        "One full pass over the entire training dataset.  \n",
        "If the dataset has 1000 samples and batch size is 100, then:  \n",
        "$$\n",
        "1 \\text{ epoch} = \\frac{1000}{100} = 10 \\text{ iterations}\n",
        "$$\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media.geeksforgeeks.org/wp-content/uploads/20241024155237307614/epoch-in-machine-learning_.webp\" width=\"600\"/>\n",
        "</p>\n",
        "\n",
        "<p align=\"center\"><b>Figure: Epoch in Machine Learning</b></p>\n",
        "\n",
        "---\n",
        "\n",
        "### Training Process Overview\n",
        "\n",
        "1. **Start Training:** Initialize model parameters.\n",
        "\n",
        "2. For each epoch (repeat multiple times):\n",
        "\n",
        "   - Divide data into batches according to batch size.  \n",
        "   \n",
        "   - For each batch:  \n",
        "     - Perform forward pass to calculate predictions.  \n",
        "     - Calculate loss based on predictions and true labels.  \n",
        "     - Perform backward pass (backpropagation) to compute gradients.  \n",
        "     - Update weights using gradients (e.g., gradient descent).\n",
        "\n",
        "\n",
        "3. Repeat until model performance stabilizes or desired accuracy is reached.\n",
        "\n",
        "\n",
        "<p>\n",
        "  <img src=\"https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TFKm_XC2dIk36i80drQ0KA.png\" width=\"600\"/>\n",
        "</p>\n",
        "\n",
        "<p>\n",
        "  <b>Figure:</b> In the Input Training Dataset step, as different kinds of strategies, we can assign a Batch Size to determine how many training datasets are going to be used for one weights updating process. For example, there are 5000 images in total as the training datasets. If we set the Batch Size = 1000, we get 5 batches of training datasets. As a result, the weights updating process will be executed 5 times (Iterations).\n",
        "</p>\n",
        "\n",
        "<p><em>Ref: <a href=\"https://medium.com/@crazyhatcap/epoch-batch-size-iteration-in-neural-network-training-process-bee58415eb8e\" target=\"_blank\">medium.com/@crazyhatcap</a></em></p>\n",
        "\n",
        "\n",
        "## Chapter Summary\n",
        "In this chapter, we explored the key components of training neural networks, including the forward and backward passes, how loss guides learning, and how weights are updated iteratively. We also discussed the role of batch size, iterations, and epochs in organizing the training process for efficient and effective learning.\n",
        "\n",
        "Understanding these concepts lays the foundation for building, training, and optimizing deep learning models. In the next chapter, we will delve into advanced optimization techniques and strategies to further improve model performance."
      ],
      "metadata": {
        "id": "kaC2y5rYGfCz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hwa3O7uaX73Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Knowledge Check\n",
        "\n",
        "<iframe src=\"https://docs.google.com/forms/d/e/1FAIpQLSdWDTzfBm1pC7w07wLKetrKKxVlzdEz-D-feCfFYemssJeVAA/viewform?embedded=true\" width=\"640\" height=\"1078\" frameborder=\"0\" marginheight=\"0\" marginwidth=\"0\">Loading…</iframe>"
      ],
      "metadata": {
        "id": "vTONdaP1Xv3U"
      }
    }
  ]
}